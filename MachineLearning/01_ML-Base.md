# 机器学习



**机器学习（Machine Learning）**，基于一些数据，产生一个模型，即学习算法，通过得到的算法模型对一些未发生的事情进行预测。



## 1.基本术语

要进行机器学习，首先需要一些数据，这些数据组成的集合称为**数据集(data set)**。在数据集中，每一条数据都是对一个事件或对象的描述，称为一个“**示例(instance) / 样本(sample)**”。每个示例都有不同的性质称为**属性(attribute) / 特征(feature)**, 舒心张成的空间称为**样本空间(sample space)**。由于空间中每个点对应一个坐标向量，因此把一个示例称为一个**特征向量(feature vector)**.

$D = \{x_1,x_2,x_3,\dots,x_m\}$，表示包含m个示例的数据集，每个示例有d个属性描述，则每个示例 $x_i = (x_{i1};x_{i2};\dots;x_{id})$ 是d维的样本空间 $\chi$ 中的一个向量， $x_i\in\chi$ ，其中 $x_{ij}$ 是 $x_i$ 在第 j 个属性上的取值，d称为样本 $x_i$ 的 **维数(dimensionality)**.

* **训练集(training set):** 训练过程中使用的数据组成的数据集合称为训练集
* **测试集(testing set):** 用于测试训练后的模型的数据集合
* **分类(classification)：** 机器学习中的一类问题，若要预测的是离散值，例如 “好瓜” “坏瓜”,此类学习任务称为分类。
* **回归(regression)：** 要预测的是连续值，例如西瓜的成熟度 0.95、0.37，此类学习任务称为回归。

* **监督学习(supervised lerning) / 无监督学习(unsupervised learing):** 根据训练数据是否拥有标记信息，将学习任务大致分为这两类。



## 2. 模型评估与选择

### 2.1 误差和过拟合

* **误差**

  错误率： $E=a/m$ ,表示在m个样本中有a个样本分类错误，精度： $accuracy=1-E$ .更一般的，把学习器的实际预测输出与样本的真实输出之间的差异称为**误差**，在训练集上的误差称为**训练误差/经验误差**

* **过拟合、欠拟合**

  ![image-20210527171456879](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210527171456879.png)





### 2.2  训练集S和测试集T的产生

1. **留出法**

   留出法(hold-out)直接将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$ , 另一个作为测试集 $T$ ,即 $D=S \cup T, S\cap T=\oslash$, 在 $S$ 上训练出模型后，用 $T$ 来评估其测试误差，作为对泛化误差的估计。

2. **交叉验证法**

   将数据集 $D$ 划分为 $k$ 个大学相似的互斥子集，即 $D = D_1\cup D_2 \cup \dots \cup D_k, D_i \cap D_j = \oslash(i\neq j)$.每个子集 $D_i$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后，每次用 $k-1$ 个子集的并集作为训练集，余下的那个子集做为测试集，这样就可获得 $k$ 个测试结果，最后取平均值作为最终的测试结果。

![image-20210527174309548](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210527174309548.png)



3. **自助法**

   以自助采样发为基础，给定 $m$ 个样本的数据集 $D$ ,从 $D$ 中去一个数据放入 $D'$ 中，再将取出的样本放回 $D$ 中。重复 $m$ 次就得到包含 $m$ 个数据的 $D'$ . 样本在 $m$ 次采样中始终不被采到的概率是 $(1-\frac {1}{m})^m$ ,取极限得到：
   $$
   \lim_{m\to\infty} (1-\frac{1}{m})^m = \frac{1}{e} \approx 0.368
   $$
   即通过自助采样，初始数据集 $D$ 中约有 36.8% 的样本未出现在采样数据集 $D'$ 中。



### 2.3 性能度量

对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的评价标准，这就是性能度量。

* **均方差**

  数据集 $D=\{(x_1,y_1),(x_2,y_2),\dots,(x_m,y_m)\}$ ,其中 $y_i$ 是示例 $x_i$ 的真实标记，要评估学习器 $f$ 的性能，把预测结果 $f(x)$ 与真实标记 $y$ 进行比较，回归任务最常用用的性能度量是均方差:
  $$
  E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2
  $$
  一般的，对于数据分布 $D$ 和概率密度函数 $p(·)$ ，均方差可描述为
  $$
  E(f;D)=\int_{x\sim D}(f(x)-y)^2p(x)dx
  $$
  
* **错误率与精度**

  错误率是分类错误的样本占样本总数的比例，精度则是分类正确的样本数占总数的比例，对样例集 $D$ ,分类错误率定义为
  $$
  E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\mathbb{I}(f(x_i)\neq y_i)
  $$
  精度定义为
  $$
  acc(f;D)= \frac{1}{m}\sum_{i=1}^{m}(f(x_i)=y_i)\\
  =1-E(f;D)
  $$
  更一般的，对于数据分为 $D$ 和概率密度函数 $p(·)$,错误率和精度可分别描述为
  $$
  E(f;D)=\int_{x\sim D} \mathbb{I}(f(x)\neq y)p(x)dx
  $$
  
  $$
  acc(f;D)=\int_{x\sim D}\mathbb{I}(f(x)=y)p(x)dx\\
  =1-E(f(x);D)
  $$
  
* 查准率、查全率

  以Web搜索为例，搜索的信息中有多少比例是用户感兴趣的，用户感兴趣的有多少杯检索出来了。对应的指标分别叫做查准率，查全率。

  在二分类的问题中，分类结果的混淆矩阵如下表

![image-20210528120247988](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210528120247988.png)

​		查准率 $P$ 与查全率 $R$ 分别定义为
$$
P = \frac {Tp}{TP+FP}
$$

$$
R=\frac{TP}{TP+FN}
$$

​		查准率和查全率是一堆矛盾的度量，即两者不可能同时高，必有一方高另一方低。以查准率为纵轴、查全率为		横轴作图，就得到查准率-查全率曲线（$P$-$R$ 曲线）

![image-20210528121109486](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210528121109486.png)

​		通过$P$-$R$ 曲线判断学习器的性能，若一个学习器的$P$-$R$ 曲线被另一个学习器的曲线包住，则后者的性能优于前		者。对于两条交叉的曲线，可比较 $P$-$R$ 曲线下的面积，但是这个值不太容易估算，引入平衡点（Break-Even 		Point，简称BEP）这样一个度量，它是“查准率 = 查全率” 时的取值，如上上图的曲线中，基于BEP的比较，可		得出A优于B.

​		但BEP过于简化，更常用的是 $F1$ 度量
$$
F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}
$$
​		$F1$ 度量的一般形式——$F_\beta$ ,能表达出对查准率/查全率的不同偏好，它的定义为
$$
F_\beta = \frac{(1+\beta^2)\times P \times R}{(\beta^2\times P)+R}
$$
​		其中 $\beta > 0$ 度量了查全率对查准率的相对重要性，$\beta =1$ 时退化为标准的 $F1$ ; $\beta >1$ 时查全率有更大影响； 		$\beta < 1$ 时查准率有更大影响。

​		

* **ROC与AUC**

  $ROC$ 全称是“受试者工作特征”（Receiver Operating Characteristic）曲线，$ROC$ 曲线分别是以“真正例率”(TPR)为纵轴，以“假正例率”(FPR)为横轴，两者的定义为：
  $$
  TPR=\frac{TP}{TP+FN}
  $$

  $$
  FPR=\frac{FP}{TN+FP}
  $$

  如图，画出的 $ROC$ 曲线，在 $ROC$ 曲线中判断学习的优劣，是通过 $ROC$ 曲线下的面积，即 $AUC$ (Area Under ROC Curve).

  ![image-20210528153952757](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210528153952757.png)

  在上图b中 $AUC$ 可估算为
  $$
  AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)·(y_i+y_{i+1})
  $$

