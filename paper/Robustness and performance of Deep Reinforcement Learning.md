# 强化学习的鲁棒性和性能

site： [Robustness and performance of Deep Reinforcement Learning ](https://www.sciencedirect.com/science/article/abs/pii/S1568494621002180)



## 〇、摘要

RL+DL可以处理各种困难的任务。本文提出了一种新的方法叫做==Genetic Algorithm of Neuron Coverage (GANC，神经元覆盖的遗传算法)==。它可以改善DRL网络的鲁棒性个性能，GANC使用遗传算法（GA），通过产生增强的输入，使DRL网络的神经元覆盖率（NC）最大化。





## 一、介绍

对于DRL，DL是用来解决RL中的MDP问题。DL是一种先进的人工神经网络，在很多领域都有应用，比如图像处理，信号处理，对象跟踪。自动驾驶是安全要求高的应用，一个具有鲁棒性的模型和方法是非常重要的，因为任何不适当的行为都会造成严重的风险，损失甚至灾难。一个高精度的模型仍然可能容易失效，在图像上细微的改变就可能导致不同的分类结果。

因此，评估模型的质量时，我们不能只考虑性能，还应该考虑鲁棒性。性能用于度量模型的总体精度，鲁棒性是接受宽范围测试数据的能力。

在本文中，我们提出在不同的自动驾驶环境中提高深度强化学习道路跟踪（DRL-RT）的性能和稳健性。通过建立新的输入样本，可以纠正错误的（或有缺陷的）跟踪预测，从而增强鲁棒性。从技术上讲，鲁棒性是由神经元覆盖率（NC）--网络中被激活的神经元的比率来衡量的 。原则上，NC的增加意味着网络中激活的神经元数量的增加，它将产生高的结果值并提高网络的总体性能。简而言之，我们希望有一个高度准确的模型，在有缺陷的数据也能很好地工作。

遗传算法GA是一种用于解决有约束和无约束的优化问题的方法。GA模拟人类基因的行为（单个染色体的选择、交叉和变异），以优化特定的适应度函数。适应度函数是评估一个给定的问题与所需问题的最优解决方案的接近程度。GA试图通过启发式方法搜索初始解的邻域来获得问题的最优解。交叉和变异操作保证人们可以改进初始解以获得全局最优解。GA技术可以在（使用了DRL网络的系统）优化NC值方面发挥有效作用。

为了将GA应用到我们的环境中，我们将NC指标作为一个适应度函数，并试图使其值最大化，然后以此来提高性能。在GA过程中，变异和交叉操作将产生更多的训练样本作为增强的输入。这些训练输入将识别出不正确的训练测试数据，并具有非常高的NC值，从而提高模型的稳健性。新生成的训练输入与原始训练集一起被用于我们提出的道路跟踪模型中。据观察，在测试阶段可以获得性能上的明显提升。

最后，我们提出了神经元覆盖的遗传算法（GANC）方法，它可以提高DRL网络的性能和鲁棒性。作为一个案例研究，我们将GANC应用于自动驾驶场景下的DRL-RT网络[6]。





## 二、文献回顾

在一些研究中，存在不同的指标来衡量深度网络的性能和/或稳健性。我们将这些研究归纳为两类--使用NC作为其衡量标准的（部分）或不使用NC。此外，他们应用鲁棒性和/或性能的标准在下表中得到了简要的说明。此外，本节还研究了GA策略。

![image-20210802104356236](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210802104356236.png)





### 2.1 没有NC的研究

1. Sun等人提出了四个基于修正条件/决策覆盖率（MC/DC）的DL网络测量标准[19]，它们是标志-标志覆盖率、距离-标志覆盖率、标志-价值覆盖率和距离-价值覆盖率。建议使用一个大的数据集来计算覆盖神经元对的百分比作为性能。而鲁棒性是通过覆盖率测试和对抗性百分比来衡量的[13]。
2. Ma等人提出了用于DL网络变异测试的DeepMutation方法。这项工作的重点是在DL网络上应用不同类型的突变。准确率的百分比被用来评估性能。同时，应用突变技术和分析测试数据和决策边界之间的关系被用来评估稳健性[14]。
3. Bai等人在寻路训练方面为白盒深Q网络（DQN）生成了对抗性样本。作者利用DQN通过搜索最优（最短）路径为机器人规划路径。此外，还生成了噪音障碍，并对寻路进行了测试。由于训练效率降低，机器人无法遵循最优路径。这里只考虑了性能，计算了不同训练时间下的准确性[15]。

### 2.2 有NC的研究

1. Pei等人提出了Deepxplore方法用于自动白盒测试。DeepXplore具有复杂的结构，因为必须使用多个DL网络。输入的种子需要来自测试样本。确定的阈值被建议用来检测活跃的神经元。通过利用两个指标对DeepXplore的性能进行了评估：产生差异诱导输入的执行时间和产生的测试的NCs。另一方面，DeepXplore本身被提议作为一种鲁棒性方法[9]。
2. 同样，Pei等人采用固定阈值来探索有效的DL神经元。在这项工作中，采用了VERIVIS框架作为黑箱模型。作者描述了从各种攻击者那里确定安全DL属性的能力。这项工作的重点是黑盒测试。时间被认为是一个性能指标。相比之下，通过采用各种变换函数，然后重新训练变换后的图像，鲁棒性得到了加强[16]。
3. Ma等人提出了一个DeepGauge模型，用于彻底衡量DL网络的稳健性。该方法考虑了两个层面的覆盖标准--神经元层面和层层面。对于神经元水平的覆盖标准，各种覆盖被表示为：K-multisection覆盖、强神经元激活覆盖和神经元边界覆盖。对于层级的覆盖标准，定义了多种覆盖：Top-k NC和Top-k神经元模式。对上述所有标准都考虑了测试样本。本文只考虑了稳健性[17]。
4. Tian等人提出Deeptest模型作为自动驾驶汽车的DL网络测试方法。在这项研究中，已经说明了增加NCs会增加DL系统的安全关键性。DeepTest调查了许多可能导致系列驾驶汽车碰撞的错误情况。在本文中，只考虑了鲁棒性，这可以通过应用不同类型的图像变换函数，然后重新训练所产生的变换图像来加强[18]。通过这种方式，不同的角落情况将被接受。
5. Sun等人解释了DL系统的协同测试，称为DeepConcolic。它能够收集覆盖要求作为启发式执行的输入。采用了不同类型的覆盖区域。这些是确定激活ReLU节点的激活模式，通过利用定量线性算术（QLAR）的一个片段来正式确定测试覆盖率标准，并将测试覆盖率指标作为安全置信度的代理指标来使用。此外，五个不同的具体覆盖率要求被应用。它们是Lipschitz连续性[20]、NC[9]、MC/DC[19]和神经元边界覆盖[17]。DeepConcolic还提供了对抗性测试样本。这项工作中提出了一个鲁棒性神谕，作为检查鲁棒性的防御性方法[7]。

> 2-5机翻



### 2.3 GA的研究

1. Mangano提供了GA的基本原理，此外还说明了GA的历史、理论、应用、实施和未来预期[21]。
2. Mishra等人回顾了GA的另一个版本，即多目标遗传算法（MOGA）。MOGA专注于采用一个以上的健身函数--至少需要两个健身函数。这里的GA可以同时处理不止一个搜索空间[22]。
3. Vuolio等人解释了一种基于GA的模型选择，用于识别基于碳化物的热金属脱硫。利用了一个单隐层前馈神经网络。一个同时进行的变量优化和隐藏神经元数量的选择被应用于GA[23]。
4. Połap建议在卷积分类器的级联和GA之间采用一种自适应的组合方法。对显微镜图像的分析是重点。GA被用作神经网络分类器选择的一个指标[24]。
5. Leonori等人说明了GA的优化策略。研究了微电网能源管理系统。事实上，一个微电网的模糊逻辑被接近了。在优化方面，研究了GA和模糊推理系统（FIS）的组合[25]。

### 2.4 论文贡献

从文献回顾中可以看出，目前还没有关于DRL的研究，可以衡量其鲁棒性，然后提高其性能。本文在DRL的GA和NC的基础上，设计了一种称为GANC的新方法。拟议的GANC通过应用GA来优化称为NC的稳健性测量。其结果是生成新的增强的输入图像，用于提高有问题的输入样本的DRL性能。





## 三、理论背景

一张可以很好的描述这个结构的图

![image-20210803082853031](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210803082853031.png)

### 3.1 DRL

DRL是结合了RL和DL的网络。原则上，有两种基本类型的RL方法--策略搜索和价值函数。第一种类型是指考虑搜索最优策略π ∗的方法。第二种类型是指考虑研究最优价值状态函数V ∗(s)的方法[2]。在这项工作中，采用的DRL网络是基于策略搜索的。根据MDP的概念，DRL收集输入图像作为当前状态St，并通过获取奖励R，产生预测新状态St+1的行动A。随后，新的状态可以作为当前状态在输入中再次转换。策略搜索的公式表示如下：
$$
\pi ^*= \underset{\pi}{arg\ max}\ \mathbb E[R|\pi]
$$
其中 $\pi$​ 是策略，$\mathbb E$​​ 是预期收益值





### 3.2 NC（Neuron coverage）

人工神经网络由称为神经元或节点的小单元组成[27]。每个神经元都可以被看作是一个人工节点。它分析输入值并产生一个输出决策[28]。在一个神经元网络中，给定一个阈值 $thr$​​ 和一个测试集 $T$​​，如果一个神经元对任何确定的输入的输出大于$thr$​​，则该神经元被认为是激活的，反之亦然。公式表示神经元 $n$​​ 被激活，$if\ out(n,x) > thr\  \text{for any testing input}\ x\in T$​​,  其中 $out(n,x)$​​ 是一个函数，返回神经元 $n$​​ 在输入 $x$​​ 下的结果值。

直观地说，NC被定义为激活的神经元数量与所有使用神经元数量之间的比率[18]。具体来说，
$$
NCov=\frac{|\{n\in N|\forall_X \in T.\ out(n,x) > thr \}|}{|N|}
$$
其中 $N=\{n_1,n_2,\dots\}$​ 是DL网络中的神经元集合，$NCov(T)$​ 表示给定的测试输入  $T=\{X_1,X_2,\dots\}$​ . 一般 $|\cdot|$​ 表示一个集合的基数（或势，就是一个集合中元素的个数），粗体 $\boldsymbol X$​​ 表示一个向量​​，这个函数会在后面的GA的适应度函数使用。

我们将会使用NC来测量鲁棒性。通过最大化NC的值，鲁棒性和性能都可以提高。这种类型的研究以前没有针对DRL网络进行过研究，我们将把DL网络视为最接近的网络类型。

如果整个网络更加活跃，DL网络将更加稳健。一个DL网络的性能或整体准确性可以通过增加NC来提高[18]。[16]中也采用了类似的方法，即采用固定的阈值来探索有效的DL网络神经元。我们将在下一节中探讨如何使用GAs来最大化NC。



### 3.3 NC 作为GA的适应度函数

GA是一种智能优化技术，它模拟人类的基因行为，并寻求某种健身函数的最佳解决方案。GA首先选择两组数字（模仿个人染色体），称为世代，并将其视为父母。然后，它进行交叉和/或变异操作，将生成的编码数字作为子代。最接近适应度函数的子代被选为新的父代。该算法重复进行，直到收敛。

我们的贡献之一是将NC的定义调整为公式（3），使其也考虑到小的嵌入值 $p_{i,j,k}$​​。这些值被添加到原始输入矢量中，并对原始图像视图进行轻微改变。新输入的NC值比原始输入的NC值高，因为GA会使新输入的NC值最大化。
$$
NewCov(T,P)=\frac{|\{n\in N|\forall_{\boldsymbol X} \in T,\boldsymbol p<P.\  out(n,\boldsymbol X + \boldsymbol P) > thr \}|}{|N|}
$$
其中 $NewCov$ 表示新的覆盖率，$T , N, thr$ 同前，$P$  是嵌入式输入的集合。$\boldsymbol X∈T$ 是测试输入向量（样本），$\bf{p}\in \mit P$是嵌入式向量。GA是将公式（3）的适应度函数最大化，并得到嵌入的$p_{i,j,k}$​值，以添加到DRL输入。



### 3.4 用GA来生成更多的训练样本

训练样本：$\boldsymbol X_{train} = \{x_{train}^1,x_{train}^2,\dots,x_{train}^n\}$​ ,测试样本 $\boldsymbol X_{test} = \{x_{test}^1,x_{test}^2,\dots,x_{test}^n\}$​​ .理想的输出值可以很容易地从原始训练和测试信息中收集到。

训练完DRL后，对测试数据进行评估。如果预测的输出与期望的输出不同，我们称之为有缺陷的测试样本。有故障的测试样本是至关重要的，因为它们能找出现有训练样本和模型的弱点。为了提高DRL的性能，我们必须关注有缺陷的测试样本，因为测试缺陷主要是由训练集中缺乏代表性造成的。

在本文中，我们将使用GA来生成增强的训练样本，这些样本可以纠正有缺陷的测试结果。因此，为了产生更有效的训练向量，需要在原始训练样本和有故障的测试案例之间建立起关系。一些训练样本不能强制DL网络获得期望的测试输出。换句话说，在失败的训练样本和其期望的测试输出之间存在着一种潜在的关系。我们首先需要检测这种关系并确定失败的训练输入，然后，我们需要建立其他的训练向量，在测试阶段有效地执行DL网络。

如果没有这些样本，模型在测试阶段会做出错误的预测输出，我们称之为有效训练样本。这些新的有效训练样本为模型增加了多样性，并减少了概括性错误。

在[29]中，Zhang等人通过以下距离指标定义了训练数据集和测试样本之间的 "相似性"
$$
D(x_{test}^j,\boldsymbol X_{train}) \coloneqq \frac{1}{k}\sum_{i=1}^{k} \lVert h(x_{test}^j)-h(x_{train}^{\pi_{j}(i)})\lVert
$$
 $k$ 表示 k 邻近， $x_{test}^j$ 是第 $j$ 个测试数据， $\lVert \cdot \lVert_p$ 表示p的范数， $h(x)$ 是使用的DL网络， $\pi_j:[n]\rightarrow [n]$ 是  $\{ \pi_j(1),\pi_j(2), \dots,\pi_j(n)\}$ 根据训练样本与 $\ell p$ 空间中第 $j$ 个测试数据样本之间的Minkowski 范数距离对训练样本进行的升序排列。

这启发了我们去研究有缺陷的测试输入和其最近的训练输入之间的关系，这些输入具有相同的目标或期望输出。如果有相同的输出，我们进一步缩小有缺陷的测试输入和其最近的训练输入之间的关系。因此，我们修改了公式（4），增加了一个条件，即最近的训练和测试样本具有相同的目标值，如下所示：
$$
D(x_{test}^j,\boldsymbol X_{train}) \coloneqq \{\frac{1}{k}\sum_{i=1}^{k} \lVert h(x_{test}^j)-h(x_{train}^{\pi_{j}(i)})\rVert\  \lvert x_{test}^j \ and \ x_{train}^{\pi_{j}} \Rightarrow t_j \}
$$
其中$t_j$代表有故障的第$j$​​​个测试的目标。重要的是要考虑最近的训练向量和造成错误结果的测试输入。然后修改这些训练向量，以提高整个系统的准确性。





### 3.5 GA如何在我们的设定中工作

使用GA的搜索算法查找新的训练输入添加到原有的输入中可以使NC的值最大化，基因的大小和输入训练样本的大小一致。每一个基因的初始化是在原有的基础上随机的添加了0或1。然后，迭代GA算法，直到收敛到最佳的状态，即产生增强型输入样本。所有的新样本通过NC适应度函数评估。将评估结果按从高到低排序，选择两个NC值最高的作为父代，因为这两个比其他更接近最优解。随后，交叉和变异可以在每次迭代中实现。根据人类基因的行为，实施交叉概率很高，实施变异过程的概率很低。使用==散点交叉法==，如图

![image-20210803154353049](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210803154353049.png)

==均匀突变==，第一个父染色体比第二个更接近目标，所以变异被用于第二个染色体以提高其结果。

![image-20210803154856063](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210803154856063.png)

### 3.6 GANC 算法

算法的流程图



![image-20210803112555501](https://kinvy-images.oss-cn-beijing.aliyuncs.com/Images/image-20210803112555501.png)

算法优点：

1. 最大化DRL的NC，可以提高性能
2. 每次运行GA都可以生成更多不同的输入，这些输入比原有的输入具有更高的NC值
3. 训练数据可以代替测试数据，后者可能无法提供全面的测量。这就克服了以前的研究，在以前的研究中，DL网络的稳健性总是只根据测试输入来衡量。
4. 应用范围广，可用于其他多层网络，比如MLP，CNN，AEN









### 3.7 . 利用DRL-RT模型
